{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from itertools import product\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала надо где то взять отзывы. Для этой цели я выбрал раздел смартфоны магазина днс, откуда смог взять 471 отзыв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first = 'https://www.dns-shop.ru/catalog/17a8a01d16404e77/smartfony/?p=1&i=1'\n",
    "addressp1 = 'https://www.dns-shop.ru/catalog/17a89fea16404e77/smartfony/?p='\n",
    "addressp2 = '&i=1'\n",
    "main = 'https://www.dns-shop.ru'\n",
    "links = [addressp1 + str(i) + addressp2 for i in range(1, 49)]\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',}\n",
    "\n",
    "def parse_reviews_page(page, file):\n",
    "    bsr = bs4.BeautifulSoup(page, 'lxml')\n",
    "    reviews = bsr.find_all('div', attrs={'class': 'opinion-item'})\n",
    "    for r in reviews:\n",
    "        rating = float(r.find('div', attrs={'class': 'product-item-rating rating'})['data-rating'])\n",
    "        text = [i.text for i in r.find_all('span', attrs={'class': 'description-text'})]\n",
    "        if rating >= 4:\n",
    "            try:\n",
    "                review = text[0] + ' ' + text[2] if len(text) == 2 else text[0]\n",
    "                file.write(review + ';;;' + str(1) + '\\n')\n",
    "                print('DONE! 1')\n",
    "            except:\n",
    "                continue\n",
    "        elif rating <= 2:\n",
    "            try:\n",
    "                review = text[1] + ' ' + text[2] if len(text) == 2 else text[1]\n",
    "                file.write(review + ';;;' + str(0) + '\\n')\n",
    "                print('DONE! 0')\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "def parse_mobile_list(page, file):\n",
    "    bs = bs4.BeautifulSoup(page, 'lxml')\n",
    "    divs = bs.find(name='div', \n",
    "                   attrs={'class': 'catalog-items-list view-list'}).find_all(name='div',\n",
    "                                                                             attrs={'class': 'item'})\n",
    "    phone_links = [main + i.find('div', attrs={'class': 'title'}).find('a')['href'] + 'opinion/' for i in divs]\n",
    "    for l in phone_links:\n",
    "        time.sleep(np.random.randint(1, 4, 1)[0])\n",
    "        page = req.get(l, headers=headers).text\n",
    "        parse_reviews_page(page, file=file)\n",
    "\n",
    "with open('dns-reviews_smart.txt', 'w') as f:\n",
    "    for i, link in enumerate(links):\n",
    "        print(i)\n",
    "        time.sleep(np.random.randint(1, 4, 1)[0])\n",
    "        page = req.get(link, headers=headers).text\n",
    "        parse_mobile_list(page, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Теперь считываем данные из файла\n",
    "data = []\n",
    "with open('dns-reviews_smart.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append([line.split(';;;')[0], int(line.split(';;;')[1])])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "with open('test.csv', 'r', encoding='utf-8') as file:\n",
    "    reviews_str = file.read()\n",
    "    bs = bs4.BeautifulSoup(reviews_str, 'lxml')\n",
    "    for r in bs.find_all('review'):\n",
    "        test.append(r.text)\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Теперь надо обработать данные. Так как отзывы в выборке также придется обрабатывать, \n",
    "# то можно обработку оформить в виде класса, который можно будет передавать в пайплайн\n",
    "class ReviewTransformer(TransformerMixin):\n",
    "    def fit(self, data, labels):\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        import re\n",
    "        creviews = []\n",
    "        for review in data:\n",
    "            rev = re.sub('\\W+', ' ', review).strip().split(' ')\n",
    "            for word in rev:\n",
    "                if re.match('[a-z]', word):\n",
    "                    word = word.lower()\n",
    "            creviews.append(' '.join(rev))\n",
    "        #print('Review transform completed')\n",
    "        return creviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что данные, полученные через парсинг сайтов и данные, полученные с кагла, как тестовая выборка имеют одинаковый вид после преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Один динамик на вызов и разговор тебя и собеседника слышен всем вокруг даже если нет желания слушать нет подсветки клавиатуры очень легкий почти невесомый нет в комплектации зарядного устройства качество сборки качество клавиатуры слабый разъем для наушников']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ReviewTransformer()\n",
    "t.transform(data[:1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['я любительница громкой музыки Тише телефона у меня еще не было Приложений мало память маленькая Толком ни чего скачать не можешь Вечно приходится что то удалять Бывало такое что сенсор заедал без особых на то причин Телефону 1 5 месяца Есть телефоны намного лучше НЕ БЕРИТЕ Я пожалела']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.transform(test[3:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее я определяю другие самописные шаги пайплайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Корреляционный фильтр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CorrTransformer(TransformerMixin):\n",
    "    def __init__(self, corr_limit=0.01, correlation='pearson'):\n",
    "        if correlation not in ['pearson', 'matthews', 'kendall', 'none']:\n",
    "            raise ValueError('Correaltion must have \"pearson\" or \"matthews\" value')\n",
    "        self.corr_limit = corr_limit\n",
    "        self.corr = correlation\n",
    "        self.coefs = []\n",
    "        \n",
    "    def __matthews_corr__(self, arr1, arr2):\n",
    "        if len(arr1) != len(arr2):\n",
    "            raise ValueError('lenths of arrays must be same')\n",
    "        from math import sqrt\n",
    "        a, b, c, d = 0, 0, 0, 0\n",
    "        for e, i in zip(arr1, arr2):\n",
    "            if e == 0 and int(i) == 0:\n",
    "                a += 1\n",
    "            elif e == 0 and int(i) == 1:\n",
    "                b += 1\n",
    "            elif e != 0 and int(i) == 0:\n",
    "                c += 1\n",
    "            elif e != 0 and int(i) == 1:\n",
    "                d += 1\n",
    "        if a + b + c + d != len(arr1):\n",
    "            raise ValueError('Counting Error')\n",
    "        S = (a + b) / len(arr1)\n",
    "        P = (a + c) / len(arr1)\n",
    "        N = len(arr1)\n",
    "        return ((a / N) - S * P) / sqrt(P * S * (1 - P) * (1 - S))\n",
    "        \n",
    "    def fit(self, data, labels, *args):\n",
    "        corrcoefs = []\n",
    "        if self.corr == 'pearson':\n",
    "            corrcoefs = [np.corrcoef(data[:, i].toarray().ravel(), [int(i) for i in labels])[0, 1] \n",
    "                        for i in range(data.shape[1])]\n",
    "        elif self.corr == 'matthews':\n",
    "            corrcoefs = [self.__matthews_corr__(data[:, i].toarray().ravel(), labels) \n",
    "                        for i in range(data.shape[1])]\n",
    "        elif self.corr == 'kendall':\n",
    "            corrcoefs = [pd.DataFrame(\n",
    "                np.stack((data.toarray()[:, i], np.array([int(l) for l in labels])), axis=1)).corr('kendall').as_matrix()[1, 0] \n",
    "                        for i in range(data.shape[1])]\n",
    "            print('corr')\n",
    "        elif self.corr == 'none':\n",
    "            corrcoefs = [1 for i in range(data.shape[1])]\n",
    "        self.coefs = np.array(corrcoefs)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data, *args):\n",
    "        indexes = [i for i in range(len(self.coefs)) if abs(self.coefs[i]) > self.corr_limit]\n",
    "        #print('Correlation transform completed')\n",
    "        return data[:, indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Преобразователь слов на основе stemmer типа snowball из библиотеки nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StemmerTransformer(TransformerMixin):\n",
    "    def __init__(self, stemmer='snowball'):\n",
    "        if stemmer not in ['snowball']:\n",
    "            raise ValueError('stemmer must have showball, lancaster or porter value')\n",
    "        self.stemmer = stemmer\n",
    "    \n",
    "    def fit(self, *args):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data, *args):\n",
    "        if self.stemmer == 'snowball':\n",
    "            from nltk.stem import SnowballStemmer\n",
    "            stemmer = SnowballStemmer(language='russian')\n",
    "        else: return\n",
    "        new_data = []\n",
    "        for doc in data:\n",
    "            import re\n",
    "            clear_doc = re.split(r'[\\s]',  doc)\n",
    "            words = [stemmer.stem(word.strip()) for word in clear_doc if word.strip() != '']\n",
    "            new_data.append(' '.join(words))\n",
    "        #print('Stem transform completed')\n",
    "        return np.array(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура модели понятна, можно начать подбирать параметры (Не запускайте следующую ячейку. Она выполняется долго)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram, analyzer, alpha, corr_limit, correlation\n",
      "(1, 1) word 0.1 0.001 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.001 matthews\n",
      "0.8066011716252582\n",
      "(1, 1) word 0.1 0.001 pearson\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.012 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.012 matthews\n",
      "0.8066011716252582\n",
      "(1, 1) word 0.1 0.012 pearson\n",
      "0.8073891936898762\n",
      "(1, 1) word 0.1 0.023000000000000003 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.023000000000000003 matthews\n",
      "0.8042630725513811\n",
      "(1, 1) word 0.1 0.023000000000000003 pearson\n",
      "0.8042612140087758\n",
      "(1, 1) word 0.1 0.034 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.034 matthews\n",
      "0.8042519475339982\n",
      "(1, 1) word 0.1 0.034 pearson\n",
      "0.8050381110560109\n",
      "(1, 1) word 0.1 0.045000000000000005 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.045000000000000005 matthews\n",
      "0.8097699517828453\n",
      "(1, 1) word 0.1 0.045000000000000005 pearson\n",
      "0.8129072154308888\n",
      "(1, 1) word 0.1 0.05600000000000001 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.05600000000000001 matthews\n",
      "0.8011017265642151\n",
      "(1, 1) word 0.1 0.05600000000000001 pearson\n",
      "0.8121136177384555\n",
      "(1, 1) word 0.1 0.067 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.067 matthews\n",
      "0.8089801061599536\n",
      "(1, 1) word 0.1 0.067 pearson\n",
      "0.8128960991595889\n",
      "(1, 1) word 0.1 0.07800000000000001 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.07800000000000001 matthews\n",
      "0.816070428706743\n",
      "(1, 1) word 0.1 0.07800000000000001 pearson\n",
      "0.8207818866875\n",
      "(1, 1) word 0.1 0.08900000000000001 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.08900000000000001 matthews\n",
      "0.8419731993783284\n",
      "(1, 1) word 0.1 0.08900000000000001 pearson\n",
      "0.8380645618343684\n",
      "(1, 1) word 0.1 0.1 none\n",
      "0.8081734986692836\n",
      "(1, 1) word 0.1 0.1 matthews\n",
      "0.8325558590446304\n",
      "(1, 1) word 0.1 0.1 pearson\n",
      "0.8364922347903433\n",
      "(1, 1) word 0.16842105263157894 0.001 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.001 matthews\n",
      "0.8073891936898762\n",
      "(1, 1) word 0.16842105263157894 0.001 pearson\n",
      "0.8089633792765065\n",
      "(1, 1) word 0.16842105263157894 0.012 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.012 matthews\n",
      "0.8073817770116211\n",
      "(1, 1) word 0.16842105263157894 0.012 pearson\n",
      "0.8089689549043223\n",
      "(1, 1) word 0.16842105263157894 0.023000000000000003 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.023000000000000003 matthews\n",
      "0.8066197133208964\n",
      "(1, 1) word 0.16842105263157894 0.023000000000000003 pearson\n",
      "0.8097699430367623\n",
      "(1, 1) word 0.16842105263157894 0.034 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.034 matthews\n",
      "0.8058261331206286\n",
      "(1, 1) word 0.16842105263157894 0.034 pearson\n",
      "0.8050325529203608\n",
      "(1, 1) word 0.16842105263157894 0.045000000000000005 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.045000000000000005 matthews\n",
      "0.8074096026742023\n",
      "(1, 1) word 0.16842105263157894 0.045000000000000005 pearson\n",
      "0.8152712816247423\n",
      "(1, 1) word 0.16842105263157894 0.05600000000000001 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.05600000000000001 matthews\n",
      "0.8105375823553026\n",
      "(1, 1) word 0.16842105263157894 0.05600000000000001 pearson\n",
      "0.8113274542164429\n",
      "(1, 1) word 0.16842105263157894 0.067 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.067 matthews\n",
      "0.8089763890747431\n",
      "(1, 1) word 0.16842105263157894 0.067 pearson\n",
      "0.8097569944611057\n",
      "(1, 1) word 0.16842105263157894 0.07800000000000001 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.07800000000000001 matthews\n",
      "0.8168565922287555\n",
      "(1, 1) word 0.16842105263157894 0.07800000000000001 pearson\n",
      "0.8215754581416848\n",
      "(1, 1) word 0.16842105263157894 0.08900000000000001 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.08900000000000001 matthews\n",
      "0.8443298314017609\n",
      "(1, 1) word 0.16842105263157894 0.08900000000000001 pearson\n",
      "0.8396405972175213\n",
      "(1, 1) word 0.16842105263157894 0.1 none\n",
      "0.8081753572118888\n",
      "(1, 1) word 0.16842105263157894 0.1 matthews\n",
      "0.8325577175872355\n",
      "(1, 1) word 0.16842105263157894 0.1 pearson\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2ef2bfd57f75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m                ('model', MultinomialNB(alpha=alpha))])\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorr_limit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorr_limit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \"\"\"\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[0;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                        **fit_params):\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-fc82e6a83ec8>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data, labels, *args)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pearson'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             corrcoefs = [np.corrcoef(data[:, i].toarray().ravel(), [int(i) for i in labels])[0, 1] \n\u001b[1;32m---> 35\u001b[1;33m                         for i in range(data.shape[1])]\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'matthews'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             corrcoefs = [self.__matthews_corr__(data[:, i].toarray().ravel(), labels) \n",
      "\u001b[1;32m<ipython-input-32-fc82e6a83ec8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pearson'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             corrcoefs = [np.corrcoef(data[:, i].toarray().ravel(), [int(i) for i in labels])[0, 1] \n\u001b[1;32m---> 35\u001b[1;33m                         for i in range(data.shape[1])]\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'matthews'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             corrcoefs = [self.__matthews_corr__(data[:, i].toarray().ravel(), labels) \n",
      "\u001b[1;32m<ipython-input-32-fc82e6a83ec8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mcorrcoefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pearson'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             corrcoefs = [np.corrcoef(data[:, i].toarray().ravel(), [int(i) for i in labels])[0, 1] \n\u001b[0m\u001b[0;32m     35\u001b[0m                         for i in range(data.shape[1])]\n\u001b[0;32m     36\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'matthews'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'vect__ngram_range': [(1,1), (1,2), (1,3), (2,3), (3,3)],\n",
    "    'vect__analyzer': ['word', 'char', 'char_wb'],\n",
    "    'model__alpha': np.linspace(0.001, 2, 20),\n",
    "    'transformer__corr_limit': np.linspace(0.001, 0.2, 10),\n",
    "    'transformer__correlation': ['matthews', 'pearson']\n",
    "}\n",
    "#'kendall', \n",
    "print('ngram, analyzer, alpha, corr_limit, correlation')\n",
    "results = []\n",
    "for ngram, analyzer, alpha, corr_limit, corr in product([(1,1), (1,2), (1,3), (2,3), (3,3)], \n",
    "                                                        ['word'], np.linspace(0.1, 1.4, 20),\n",
    "                                                        np.linspace(0.001, 0.1, 10), ['none', 'matthews', 'pearson']):\n",
    "    pl = Pipeline([('preprocessing', ReviewTransformer()),\n",
    "               ('stem', StemmerTransformer(stemmer='snowball')),\n",
    "               ('vect', CountVectorizer(ngram_range=ngram, analyzer=analyzer)), \n",
    "               ('transformer', CorrTransformer(corr_limit=corr_limit, correlation=corr)),\n",
    "               ('model', MultinomialNB(alpha=alpha))])\n",
    "    print(ngram, analyzer, alpha, corr_limit, corr)\n",
    "    result = cross_val_score(pl, data[:, 0], data[:, 1], cv=3, scoring='accuracy').mean()\n",
    "    results.append([ngram, analyzer, alpha, corr_limit, corr, result])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Окончания работы этой ячейки я так и не дождался, но все же получил какие то результаты, а именно:\n",
    "1) Перебор надо делать с анализатором word в countvectorizer\n",
    "2) Все модели с нграммами в среднем дают качество хуже чем с униграммами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ждать полного перебора - это слишком долго, так что я решил попробовать рандомизированный перебор, но с RandomizedSearch у меня не сложилось, поэтому я написал что то вроде этого самостоятельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomizedresults = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid seacrh\n",
    "params = list(product([(1,2), (1,1)], \n",
    "                 ['word'], np.linspace(0.1, 1.4, 20),\n",
    "                 np.linspace(0.001, 0.1, 10), \n",
    "                 ['none', 'matthews', 'pearson', 'kendall']))\n",
    "max_score = 0\n",
    "while True:\n",
    "    ind = np.random.choice(range(len(params)), 1)\n",
    "    param_set = params[ind[0]]\n",
    "    pl = Pipeline([('preprocessing', ReviewTransformer()),\n",
    "               ('stem', StemmerTransformer(stemmer='snowball')),\n",
    "               ('vect', CountVectorizer(ngram_range=param_set[0], analyzer=param_set[1])), \n",
    "               ('transformer', CorrTransformer(corr_limit=param_set[3], correlation=param_set[4])),\n",
    "               ('model', MultinomialNB(alpha=param_set[2]))])\n",
    "    print(param_set)\n",
    "    result = cross_val_score(pl, data[:, 0], data[:, 1], cv=3, scoring='accuracy').mean()\n",
    "    if result > max_score:\n",
    "        best_model = pl\n",
    "        max_score = result\n",
    "    randomizedresults.append([i for i in param_set] + [result])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайплайн с параметрами ниже имеет качество 0.94 на тесте (95 место)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr\n",
      "['0' '1' '0' '0' '1' '1' '1' '1' '0' '1' '0' '0' '1' '1' '1' '1' '1' '0'\n",
      " '1' '1' '1' '0' '0' '1' '0' '0' '1' '1' '0' '1' '0' '1' '0' '1' '0' '1'\n",
      " '1' '0' '1' '0' '1' '1' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '1' '1' '1' '1' '0' '1' '0' '0' '0' '0' '0' '0' '1' '1' '1' '0'\n",
      " '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '1' '0' '0'\n",
      " '0' '1' '0' '1' '0' '0' '1' '0' '1' '1']\n"
     ]
    }
   ],
   "source": [
    "pl = Pipeline([('preprocessing', ReviewTransformer()),\n",
    "               ('stem', StemmerTransformer(stemmer='snowball')),\n",
    "               ('vect', CountVectorizer(ngram_range=(1,1), analyzer='word')), \n",
    "               ('transformer', CorrTransformer(corr_limit=0.001, correlation='pearson')),\n",
    "               ('model', MultinomialNB(alpha=0.7157894736842104))])\n",
    "pl.fit(data[:, 0], data[:, 1])\n",
    "results = pl.predict(test)\n",
    "print(results)\n",
    "dfr = pd.DataFrame(list(zip([i for i in range(len(test))], ['pos' if i == '1' else 'neg' for i in results])), columns=['Id', 'y'])\n",
    "dfr = dfr.set_index('Id')\n",
    "dfr.to_csv('results2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из главных проблем, что у меня были в процессе работы - это неправильно собранная выборка. В частности у каждого отзыва есть 3 поля: Достоинства, Недостатки и, опционально, коментарий. Сначала я в каждый отзыв клал все что есть, но потом понял, что это неверно и начал в положительные отзывы класть только достоинства, а в негативные только недостатки. Качество подскочило на 12 процентов и мне кажется, что если нормально подобрать параметры, то это не предел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
